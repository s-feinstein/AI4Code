{"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMM0p66hnQBiMG92xJEpbAy","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/s-feinstein/G2Net/blob/dev/G2Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# [G2Net](https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves/) â€“ Detecting Continuous Gravitational Waves\n\n**Objective:**\nHelp us detect long-lasting gravitational-wave signals!\n\nThe goal of this competition is to find continuous gravitational-wave signals. You will develop a model sensitive enough to detect weak yet long-lasting signals emitted by rapidly-spinning neutron stars within noisy data.\n\n**Secret Objective!!!** Receive excellent marks from this final project in [3253 - Machine Learning at U. Toronto](https://learn.utoronto.ca/programs-courses/courses/3253-machine-learning)","metadata":{"id":"7uhXOtQg9B6y"}},{"cell_type":"markdown","source":"## Authenticate with Secrets (Obsolete: Style Points Only)\nI switched from Google Colab to Kaggle notebooks because the dataset was (much) too large for Colab, so this part isn't actually necessary anymore. Kaggle offers the data directly so there's no need to authenticate with an API token. However it was neat enough I left it in, and it would be useful if I needed to manage other secrets in the future.\n\n> !wget -q -N \"https://raw.githubusercontent.com/s-feinstein/G2Net/dev/setup-colab.py\"\n>\n> %run setup-colab.py\n\n## Import the dataset (Also Obsolete when running on the Kaggle platform)\n\n\n> !pip install kaggle\n>\n> !kaggle competitions download g2net-detecting-continuous-gravitational-waves","metadata":{"id":"mX2OHrGhLqjR"}},{"cell_type":"markdown","source":"## Load the labels\n\nLoad the labels and split it into train and test","metadata":{"id":"HqZtXQOBALCY"}},{"cell_type":"code","source":"import pandas as pd\nlabels = pd.read_csv('../input/g2net-detecting-continuous-gravitational-waves/train_labels.csv')\n\n# Removing the negative labels\nlabels = labels[labels.target>=0]\n# train_labels.target.value_counts()\n# train_labels.info()\n\n# Split Data\nfrom sklearn.model_selection import train_test_split\n#train test split\ntrain_labels, test_labels = train_test_split(labels, test_size=0.3, random_state=42)\ntrain_labels.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"HQgAHj9uAM-T","outputId":"bc1ea68d-19bb-45c4-92a4-0a451b348d8b","execution":{"iopub.status.busy":"2022-11-29T17:57:27.198238Z","iopub.execute_input":"2022-11-29T17:57:27.198522Z","iopub.status.idle":"2022-11-29T17:57:27.715839Z","shell.execute_reply.started":"2022-11-29T17:57:27.198497Z","shell.execute_reply":"2022-11-29T17:57:27.714912Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 420 entries, 108 to 102\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      420 non-null    object\n 1   target  420 non-null    int64 \ndtypes: int64(1), object(1)\nmemory usage: 9.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generate list of the training file paths","metadata":{}},{"cell_type":"code","source":"import os\n\ntrain_files = []\ntrain_path = \"/kaggle/input/g2net-detecting-continuous-gravitational-waves/train\"\nfor id in train_labels.loc[:,\"id\"]:\n    filename = id + \".hdf5\"\n    path = os.path.join(train_path, filename)\n    train_files.append(path)\n    \ntrain_files[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T17:57:27.719226Z","iopub.execute_input":"2022-11-29T17:57:27.719691Z","iopub.status.idle":"2022-11-29T17:57:27.731611Z","shell.execute_reply.started":"2022-11-29T17:57:27.719656Z","shell.execute_reply":"2022-11-29T17:57:27.730494Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/g2net-detecting-continuous-gravitational-waves/train/2688e48bd.hdf5'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Explore the data","metadata":{}},{"cell_type":"code","source":"import h5py\nfile = h5py.File(train_files[0])\n\nprint(list(file.keys())[0])\nprint(file['2688e48bd'].keys())\nprint(file['2688e48bd']['H1'].keys())\nprint(file['2688e48bd']['L1'].keys())\nprint(file['2688e48bd']['frequency_Hz'])\nprint(file['2688e48bd']['frequency_Hz'][0:4])\nprint(file['2688e48bd']['H1']['timestamps_GPS'])\nprint(file['2688e48bd']['H1']['timestamps_GPS'][0], \" - \", file['2688e48bd']['H1']['timestamps_GPS'][-1])\nprint(file['2688e48bd']['H1']['SFTs'])\nprint(file['2688e48bd']['H1']['SFTs'][0:2])\nprint(file['2688e48bd']['L1']['timestamps_GPS'])\nprint(file['2688e48bd']['L1']['timestamps_GPS'][0], \" - \", file['2688e48bd']['L1']['timestamps_GPS'][-1])\nprint(file['2688e48bd']['L1']['SFTs'])\nprint(file['2688e48bd']['L1']['SFTs'][0:2])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T17:57:27.733038Z","iopub.execute_input":"2022-11-29T17:57:27.733290Z","iopub.status.idle":"2022-11-29T17:57:27.951568Z","shell.execute_reply.started":"2022-11-29T17:57:27.733266Z","shell.execute_reply":"2022-11-29T17:57:27.949236Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2688e48bd\n<KeysViewHDF5 ['H1', 'L1', 'frequency_Hz']>\n<KeysViewHDF5 ['SFTs', 'timestamps_GPS']>\n<KeysViewHDF5 ['SFTs', 'timestamps_GPS']>\n<HDF5 dataset \"frequency_Hz\": shape (360,), type \"<f8\">\n[306.92055556 306.92111111 306.92166667 306.92222222]\n<HDF5 dataset \"timestamps_GPS\": shape (4564,), type \"<i8\">\n1238170479  -  1248546822\n<HDF5 dataset \"SFTs\": shape (360, 4564), type \"<c8\">\n[[-4.5731778e-23+1.18721092e-22j  2.8206372e-23-1.11619598e-23j\n   1.1124856e-22-3.01264718e-23j ... -9.1336872e-23-1.15372359e-22j\n   4.9273540e-23+8.50121319e-23j -2.2122217e-22+7.59737612e-23j]\n [-4.5931660e-23-1.34403698e-22j  2.4227980e-23+1.09901059e-22j\n   1.7774413e-22-1.22264384e-23j ... -9.4565130e-23+2.65873464e-22j\n  -4.0620313e-23-4.09678061e-23j -7.8723440e-23-4.63299556e-23j]]\n<HDF5 dataset \"timestamps_GPS\": shape (4646,), type \"<i8\">\n1238167882  -  1248558232\n<HDF5 dataset \"SFTs\": shape (360, 4646), type \"<c8\">\n[[ 2.2248422e-22+5.95424828e-23j -1.1790475e-22-6.16426640e-23j\n   6.1226429e-23+8.86846644e-23j ... -4.7563437e-23+1.50807625e-22j\n   1.5231211e-22-3.16075486e-23j -1.2408348e-22+1.00703377e-22j]\n [ 6.6662400e-23+1.94688158e-23j  1.6869725e-22-5.63161111e-23j\n   2.3793220e-23-7.21484611e-23j ... -1.3155282e-22-9.33249966e-23j\n  -2.2897292e-22+7.13257659e-24j  3.4023306e-23-1.00261690e-22j]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the data into a dataframe","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/maharshipandya/g2net-data-and-augmentation\n\nimport numpy as np\nBASE_DIR = \"/kaggle/input/g2net-detecting-continuous-gravitational-waves/train/\"\n\nclass SFT2Img:\n    def __init__(self, labels):\n        # labels the dataframe of train labels\n        self.labels = labels\n            \n    \n    def __getitem__(self, index):\n        # get the file id from dataframe\n        lab = self.labels.iloc[index]\n        file_id = lab[\"id\"]\n        \n        # this is our label\n        y = np.float32(lab[\"target\"])\n        \n        # SFT tensor for H1 and L1 observatory (128 columns)\n        img = np.empty((2, 360, 128), dtype=np.float32)\n        \n        filename = f\"{file_id}.hdf5\"\n        with h5py.File(BASE_DIR + filename, 'r') as f:\n            group = f[file_id]\n            \n            for i, obs in enumerate(['H1', 'L1']):\n                # scaling the fourier transforms (complex64 in nature)\n                sft = group[obs]['SFTs'][:, :4096] * 1e22\n                \n                # magnitude squared\n                mag = sft.real ** 2 + sft.imag ** 2\n                \n                # normalize and reduce 4096 to 128\n                mag /= np.mean(mag)\n                mag = np.mean(mag.reshape(360, 128, 32), axis=2)\n                \n                # 0 for H1 and 1 for L1\n                img[i] = mag\n        \n        return img, y\n\n# Added a minor improvement to flatten images to instance variables\n# for easier model training\nclass Dataset:\n    def __init__(self, labels):\n        self.sft2img = SFT2Img(labels)\n        # labels the dataframe of train labels\n        self.labels = self.sft2img.labels\n        self.H1 = np.ndarray(shape=(0, 360*128))\n        self.L1 = np.ndarray(shape=(0, 360*128))\n        self.build_data()\n        self.H1L1 = np.vstack((self.H1, self.L1))\n        self.labelsH1L1 = pd.concat([self.labels, self.labels])\n        \n    def build_data(self):\n        for i in range(self.sft2img.labels.target.shape[0]):\n            img, label = self.sft2img[i]\n            H1img = np.array(img[0]).flatten()\n            L1img = np.array(img[1]).flatten()\n            self.H1 = np.vstack((self.H1, H1img))\n            self.L1 = np.vstack((self.L1, L1img))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:55:03.243101Z","iopub.execute_input":"2022-11-29T19:55:03.243476Z","iopub.status.idle":"2022-11-29T19:55:03.259271Z","shell.execute_reply.started":"2022-11-29T19:55:03.243449Z","shell.execute_reply":"2022-11-29T19:55:03.257344Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(train_labels)\ntest_dataset = Dataset(test_labels)\n            \nprint(\"Shape of the labels: \", train_dataset.labels.target.shape)\nprint(\"Shape of H1: \", train_dataset.H1.shape)\nprint(\"Shape of L1: \", train_dataset.L1.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:55:09.032464Z","iopub.execute_input":"2022-11-29T19:55:09.032822Z","iopub.status.idle":"2022-11-29T19:59:44.452638Z","shell.execute_reply.started":"2022-11-29T19:55:09.032796Z","shell.execute_reply":"2022-11-29T19:59:44.451235Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Shape of the labels:  (420,)\nShape of H1:  (420, 46080)\nShape of L1:  (420, 46080)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Evaluation\n\nSimple model evaluation for consistent testing and comparison as we try different approaches","metadata":{}},{"cell_type":"code","source":"class Performance():\n    def __init__(self, model, dataset, H1=True, L1=True):\n        self.truePos = 0\n        self.trueNeg = 0\n        self.falsePos = 0\n        self.falseNeg = 0\n        self.precision = 0\n        self.recall = 0\n        self.harmonicMean = 0\n        self.model = model\n        self.dataset = dataset\n        self.H1 = H1\n        self.L1 = L1\n        self.calculate()\n        \n    def predict_scores(self):\n        for i in range(self.dataset.labels.target.shape[0]):\n            actual = self.dataset.labels.target.iloc[i]\n            if self.H1:\n                predictedI = self.model.predict([self.dataset.H1[i]])\n                self.compare_scores(predictedI, actual)\n            if self.L1:\n                predictedL = self.model.predict([self.dataset.L1[i]])\n                self.compare_scores(predictedL, actual)\n        \n    def compare_scores(self, predicted, actual):\n        if predicted == actual:\n            if predicted >= 0.5:\n                self.truePos += 1\n            elif predicted < 0.5:\n                self.trueNeg += 1\n            else:\n                print(\"Not sure what to do with \", predicted, \" and \", actual)\n        else:\n            if predicted >= 0.5:\n                self.falsePos += 1\n            elif predicted < 0.5:\n                self.falseNeg += 1\n            else:\n                print(\"Not sure what to do with \", predicted, \" and \", actual) \n        return\n        # Fill this in later, compare each score to tally TP/FP/TN/FN\n\n    # Precision: TP / (TP + FP)        \n    def calculate_precision(self):\n        self.precision = self.truePos / ( self.truePos + self.falsePos)\n        return self.precision\n\n    # Recall: TP / (TP + FN)\n    def calculate_recall(self):\n        self.recall = self.truePos / ( self.truePos + self.falseNeg)\n        return self.recall\n    \n    # Harmonic Mean: F1 = TP / (TP + ((FN + FP)/ 2) ) = 2 * ( (Precision * Recall) / (Precision + Recall) )\n    def calculate_harmonic_mean(self):\n        self.harmonicMean = 2 * ( (self.precision * self.recall) / (self.precision + self.recall) )\n        return self.harmonicMean\n    \n    # Print the results\n    def get_results(self):\n        print(\"True Positives: \", self.truePos)\n        print(\"True Negatives: \", self.trueNeg)\n        print(\"False Positives: \", self.falsePos)\n        print(\"False Negatives: \", self.falseNeg)\n        print(\"Precision: \", self.precision)\n        print(\"Recall: \", self.recall)\n        print(\"Harmonic Mean: \", self.harmonicMean)\n        \n    # Calculate pipeline\n    def calculate(self):\n        self.predict_scores()\n        self.calculate_precision()\n        self.calculate_recall()\n        self.calculate_harmonic_mean()\n        self.get_results()   ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T20:13:21.603533Z","iopub.execute_input":"2022-11-29T20:13:21.603920Z","iopub.status.idle":"2022-11-29T20:13:21.620740Z","shell.execute_reply.started":"2022-11-29T20:13:21.603892Z","shell.execute_reply":"2022-11-29T20:13:21.619389Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Train a basic model for baseline testing\nThere's a lot of data engineering we can try with this in terms of data transformations, data alignment and normalization, selectively excluding data, etc.\nBut first, let's take a naive approach and see how a few basic models fare.\nThat way we can see if future optimizations work and how well.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nimport numpy as np\n\n#sgd stands for stochastic gradient descent (read more about GSD https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd)\n#clf stands for classifier\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(train_dataset.H1, train_dataset.labels.target)\n\nprint(\"~~~\")\nprint(\"Train H1:\")\nprint(\"~~~\")\nPerformance(sgd_clf, train_dataset, True, False)\nprint(\"~~~\")\nprint(\"Test H1:\")\nprint(\"~~~\")\nPerformance(sgd_clf, test_dataset, True, False)\nprint(\"~~~\")\nprint(\"Test L1:\")\nprint(\"~~~\")\nPerformance(sgd_clf, test_dataset, False, True)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T20:15:52.992125Z","iopub.execute_input":"2022-11-29T20:15:52.992514Z","iopub.status.idle":"2022-11-29T20:15:53.398665Z","shell.execute_reply.started":"2022-11-29T20:15:52.992488Z","shell.execute_reply":"2022-11-29T20:15:53.397742Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"~~~\nTrain H1:\n~~~\nTrue Positives:  279\nTrue Negatives:  141\nFalse Positives:  0\nFalse Negatives:  0\nPrecision:  1.0\nRecall:  1.0\nHarmonic Mean:  1.0\n~~~\nTest H1:\n~~~\nTrue Positives:  57\nTrue Negatives:  30\nFalse Positives:  29\nFalse Negatives:  64\nPrecision:  0.6627906976744186\nRecall:  0.47107438016528924\nHarmonic Mean:  0.5507246376811594\n~~~\nTest L1:\n~~~\nTrue Positives:  56\nTrue Negatives:  29\nFalse Positives:  30\nFalse Negatives:  65\nPrecision:  0.6511627906976745\nRecall:  0.4628099173553719\nHarmonic Mean:  0.5410628019323672\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"<__main__.Performance at 0x7f08d1976210>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}}]}