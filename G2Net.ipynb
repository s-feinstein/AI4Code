{"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMM0p66hnQBiMG92xJEpbAy","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/s-feinstein/G2Net/blob/dev/G2Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# [G2Net](https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves/) â€“ Detecting Continuous Gravitational Waves\n\n**Objective:**\nHelp us detect long-lasting gravitational-wave signals!\n\nThe goal of this competition is to find continuous gravitational-wave signals. You will develop a model sensitive enough to detect weak yet long-lasting signals emitted by rapidly-spinning neutron stars within noisy data.\n\n**Secret Objective!!!** Receive excellent marks from this final project in [3253 - Machine Learning at U. Toronto](https://learn.utoronto.ca/programs-courses/courses/3253-machine-learning)","metadata":{"id":"7uhXOtQg9B6y"}},{"cell_type":"markdown","source":"## Authenticate with Secrets","metadata":{"id":"mX2OHrGhLqjR"}},{"cell_type":"code","source":"!wget -q -N \"https://raw.githubusercontent.com/s-feinstein/G2Net/dev/setup-colab.py\"\n%run setup-colab.py","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fdmPvLSLuXH","outputId":"09f97683-10d9-4636-b458-c043d59c9821","execution":{"iopub.status.busy":"2022-11-29T01:00:08.686120Z","iopub.execute_input":"2022-11-29T01:00:08.686646Z","iopub.status.idle":"2022-11-29T01:00:09.941070Z","shell.execute_reply.started":"2022-11-29T01:00:08.686608Z","shell.execute_reply":"2022-11-29T01:00:09.939456Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Import the dataset","metadata":{"id":"c8Gmelta-J_r"}},{"cell_type":"code","source":"# !pip install kaggle\n\n!kaggle competitions download g2net-detecting-continuous-gravitational-waves","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uh5EmJ8v9A1Q","outputId":"716dc602-281a-4304-b21c-2fade3dee313","execution":{"iopub.status.busy":"2022-11-29T01:00:09.943849Z","iopub.execute_input":"2022-11-29T01:00:09.944605Z","iopub.status.idle":"2022-11-29T01:00:11.403598Z","shell.execute_reply.started":"2022-11-29T01:00:09.944555Z","shell.execute_reply":"2022-11-29T01:00:11.402294Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/bin/kaggle\", line 5, in <module>\n    from kaggle.cli import main\n  File \"/opt/conda/lib/python3.7/site-packages/kaggle/__init__.py\", line 23, in <module>\n    api.authenticate()\n  File \"/opt/conda/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n    self.config_file, self.config_dir))\nOSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the labels\n\nLoad the labels and split it into train and test","metadata":{"id":"HqZtXQOBALCY"}},{"cell_type":"code","source":"import pandas as pd\nlabels = pd.read_csv('../input/g2net-detecting-continuous-gravitational-waves/train_labels.csv')\n\n# Removing the negative labels\nlabels = labels[labels.target>=0]\n# train_labels.target.value_counts()\n# train_labels.info()\n\n# Split Data\nfrom sklearn.model_selection import train_test_split\n#train test split\ntrain_labels, test_labels = train_test_split(labels, test_size=0.3, random_state=42)\ntrain_labels.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"HQgAHj9uAM-T","outputId":"bc1ea68d-19bb-45c4-92a4-0a451b348d8b","execution":{"iopub.status.busy":"2022-11-29T01:00:11.405188Z","iopub.execute_input":"2022-11-29T01:00:11.405570Z","iopub.status.idle":"2022-11-29T01:00:11.429827Z","shell.execute_reply.started":"2022-11-29T01:00:11.405537Z","shell.execute_reply":"2022-11-29T01:00:11.428848Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 420 entries, 108 to 102\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      420 non-null    object\n 1   target  420 non-null    int64 \ndtypes: int64(1), object(1)\nmemory usage: 9.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generate list of the training file paths","metadata":{}},{"cell_type":"code","source":"import os\n\ntrain_files = []\ntrain_path = \"/kaggle/input/g2net-detecting-continuous-gravitational-waves/train\"\nfor id in train_labels.loc[:,\"id\"]:\n    filename = id + \".hdf5\"\n    path = os.path.join(train_path, filename)\n    train_files.append(path)\n    \ntrain_files[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:00:11.432556Z","iopub.execute_input":"2022-11-29T01:00:11.433308Z","iopub.status.idle":"2022-11-29T01:00:11.444877Z","shell.execute_reply.started":"2022-11-29T01:00:11.433261Z","shell.execute_reply":"2022-11-29T01:00:11.443818Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/g2net-detecting-continuous-gravitational-waves/train/2688e48bd.hdf5'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Explore the data","metadata":{}},{"cell_type":"code","source":"import h5py\nfile = h5py.File(train_files[0])\n\nprint(list(file.keys())[0])\nprint(file['2688e48bd'].keys())\nprint(file['2688e48bd']['H1'].keys())\nprint(file['2688e48bd']['L1'].keys())\nprint(file['2688e48bd']['frequency_Hz'])\nprint(file['2688e48bd']['frequency_Hz'][0:4])\nprint(file['2688e48bd']['H1']['timestamps_GPS'])\nprint(file['2688e48bd']['H1']['timestamps_GPS'][0], \" - \", file['2688e48bd']['H1']['timestamps_GPS'][-1])\nprint(file['2688e48bd']['H1']['SFTs'])\nprint(file['2688e48bd']['H1']['SFTs'][0:2])\nprint(file['2688e48bd']['L1']['timestamps_GPS'])\nprint(file['2688e48bd']['L1']['timestamps_GPS'][0], \" - \", file['2688e48bd']['L1']['timestamps_GPS'][-1])\nprint(file['2688e48bd']['L1']['SFTs'])\nprint(file['2688e48bd']['L1']['SFTs'][0:2])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:00:11.446425Z","iopub.execute_input":"2022-11-29T01:00:11.446834Z","iopub.status.idle":"2022-11-29T01:00:11.468584Z","shell.execute_reply.started":"2022-11-29T01:00:11.446800Z","shell.execute_reply":"2022-11-29T01:00:11.467441Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"2688e48bd\n<KeysViewHDF5 ['H1', 'L1', 'frequency_Hz']>\n<KeysViewHDF5 ['SFTs', 'timestamps_GPS']>\n<KeysViewHDF5 ['SFTs', 'timestamps_GPS']>\n<HDF5 dataset \"frequency_Hz\": shape (360,), type \"<f8\">\n[306.92055556 306.92111111 306.92166667 306.92222222]\n<HDF5 dataset \"timestamps_GPS\": shape (4564,), type \"<i8\">\n1238170479  -  1248546822\n<HDF5 dataset \"SFTs\": shape (360, 4564), type \"<c8\">\n[[-4.5731778e-23+1.18721092e-22j  2.8206372e-23-1.11619598e-23j\n   1.1124856e-22-3.01264718e-23j ... -9.1336872e-23-1.15372359e-22j\n   4.9273540e-23+8.50121319e-23j -2.2122217e-22+7.59737612e-23j]\n [-4.5931660e-23-1.34403698e-22j  2.4227980e-23+1.09901059e-22j\n   1.7774413e-22-1.22264384e-23j ... -9.4565130e-23+2.65873464e-22j\n  -4.0620313e-23-4.09678061e-23j -7.8723440e-23-4.63299556e-23j]]\n<HDF5 dataset \"timestamps_GPS\": shape (4646,), type \"<i8\">\n1238167882  -  1248558232\n<HDF5 dataset \"SFTs\": shape (360, 4646), type \"<c8\">\n[[ 2.2248422e-22+5.95424828e-23j -1.1790475e-22-6.16426640e-23j\n   6.1226429e-23+8.86846644e-23j ... -4.7563437e-23+1.50807625e-22j\n   1.5231211e-22-3.16075486e-23j -1.2408348e-22+1.00703377e-22j]\n [ 6.6662400e-23+1.94688158e-23j  1.6869725e-22-5.63161111e-23j\n   2.3793220e-23-7.21484611e-23j ... -1.3155282e-22-9.33249966e-23j\n  -2.2897292e-22+7.13257659e-24j  3.4023306e-23-1.00261690e-22j]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the data into a dataframe","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/maharshipandya/g2net-data-and-augmentation\n\nimport numpy as np\nBASE_DIR = \"/kaggle/input/g2net-detecting-continuous-gravitational-waves/train/\"\n\nclass SFT2Img:\n    def __init__(self, labels):\n        # labels the dataframe of train labels\n        self.labels = labels\n            \n    \n    def __getitem__(self, index):\n        # get the file id from dataframe\n        lab = self.labels.iloc[index]\n        file_id = lab[\"id\"]\n        \n        # this is our label\n        y = np.float32(lab[\"target\"])\n        \n        # SFT tensor for H1 and L1 observatory (128 columns)\n        img = np.empty((2, 360, 128), dtype=np.float32)\n        \n        filename = f\"{file_id}.hdf5\"\n        with h5py.File(BASE_DIR + filename, 'r') as f:\n            group = f[file_id]\n            \n            for i, obs in enumerate(['H1', 'L1']):\n                # scaling the fourier transforms (complex64 in nature)\n                sft = group[obs]['SFTs'][:, :4096] * 1e22\n                \n                # magnitude squared\n                mag = sft.real ** 2 + sft.imag ** 2\n                \n                # normalize and reduce 4096 to 128\n                mag /= np.mean(mag)\n                mag = np.mean(mag.reshape(360, 128, 32), axis=2)\n                \n                # 0 for H1 and 1 for L1\n                img[i] = mag\n        \n        return img, y\n\n# Added a minor improvement to flatten images to instance variables\n# for easier model training\nclass Dataset:\n    def __init__(self, labels):\n        self.sft2img = SFT2Img(labels)\n        # labels the dataframe of train labels\n        self.labels = sft2img.labels\n        self.H1 = np.ndarray(shape=(0, 360*128))\n        self.L1 = np.ndarray(shape=(0, 360*128))\n        self.build_data(sft2img)\n        self.H1L1 = np.vstack((self.H1, self.L1))\n        self.labelsH1L1 = np.vstack((self.labels, self.labels))\n        \n    def build_data(self):\n        for i in range(self.sft2img.labels.target.shape[0]):\n            img, label = self.sft2img[i]\n            H1img = np.array(img[0]).flatten()\n            L1img = np.array(img[1]).flatten()\n            self.H1 = np.vstack((self.H1, H1img))\n            self.L1 = np.vstack((self.L1, L1img))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T02:48:11.125753Z","iopub.execute_input":"2022-11-29T02:48:11.126294Z","iopub.status.idle":"2022-11-29T02:48:11.144724Z","shell.execute_reply.started":"2022-11-29T02:48:11.126249Z","shell.execute_reply":"2022-11-29T02:48:11.143090Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(train_labels)\ntest_dataset = Dataset(test_labels)\n            \nprint(\"Shape of the labels: \", train_dataset.labels.target.shape)\nprint(\"Shape of H1: \", train_dataset.H1.shape)\nprint(\"Shape of L1: \", train_dataset.L1.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T02:48:20.156105Z","iopub.execute_input":"2022-11-29T02:48:20.156667Z","iopub.status.idle":"2022-11-29T02:51:32.792208Z","shell.execute_reply.started":"2022-11-29T02:48:20.156621Z","shell.execute_reply":"2022-11-29T02:51:32.790295Z"},"trusted":true},"execution_count":117,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/708524641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of the labels: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of H1: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2968425451.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msft2img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH1L1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelsH1L1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2968425451.py\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, sft2img)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msft2img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msft2img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mH1img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mL1img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Dataset' object is not subscriptable"],"ename":"TypeError","evalue":"'Dataset' object is not subscriptable","output_type":"error"}]},{"cell_type":"markdown","source":"## Model Evaluation\n\nSimple model evaluation for consistent testing and comparison as we try different approaches","metadata":{}},{"cell_type":"code","source":"class Performance():\n    def __init__(self, modelOutput, expectedOutput):\n        self.truePos = 0\n        self.trueNeg = 0\n        self.falsePos = 0\n        self.falseNeg = 0\n        self.precision = 0\n        self.recall = 0\n        self.harmonicMean = 0\n        self.calculate(modelOutput, expectedOutput)\n        \n    def compare_scores(modelOutput, expectedOutput):\n        return\n        # Fill this in later, compare each score to tally TP/FP/TN/FN\n\n    # Precision: TP / (TP + FP)        \n    def calculate_precision():\n        self.precision = self.truePos / ( self.truePos + self.falsePos)\n        return self.precision\n\n    # Recall: TP / (TP + FN)\n    def calculate_recall():\n        self.recall = self.truePos / ( self.truePos + self.falseNeg)\n        return self.recall\n    \n    # Harmonic Mean: F1 = TP / (TP + ((FN + FP)/ 2) ) = 2 * ( (Precision * Recall) / (Precision + Recall) )\n    def calculate_harmonic_mean():\n        self.harmonicMean = 2 * ( (self.precision * self.recall) / (self.precision + self.recall) )\n        return self.harmonicMean\n    \n    # Print the results\n    def get_results():\n        print(\"True Positives: \", self.truePos)\n        print(\"True Negatives: \", self.trueNeg)\n        print(\"False Positives: \", self.falsePos)\n        print(\"False Negatives: \", self.falseNeg)\n        print(\"Precision: \", self.precision)\n        print(\"Recall: \", self.recall)\n        print(\"Harmonic Mean: \", self.harmonicMean)\n        \n    # Calculate pipeline\n    def calculate(modelOutput, expectedOutput):\n        compare_scores(modelOutput, expectedOutput)\n        calculate_precision()\n        calculate_recall()\n        calculate_harmonic_mean()\n        get_results()   ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:00:11.535736Z","iopub.status.idle":"2022-11-29T01:00:11.536222Z","shell.execute_reply.started":"2022-11-29T01:00:11.535965Z","shell.execute_reply":"2022-11-29T01:00:11.535985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train a basic model for baseline testing\nThere's a lot of data engineering we can try with this in terms of data transformations, data alignment and normalization, selectively excluding data, etc.\nBut first, let's take a naive approach and see how a few basic models fare.\nThat way we can see if future optimizations work and how well.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nimport numpy as np\n\n#sgd stands for stochastic gradient descent (read more about GSD https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd)\n#clf stands for classifier\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(train_dataset.H1, train_dataset.labels.target)\n\npred = sgd_clf.predict([train_H1[11]])\nprint(\"Prediction: \", pred[0])\nprint(\"Actual: \", train_dataset.labels.target.iloc[11])\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T02:23:03.314377Z","iopub.execute_input":"2022-11-29T02:23:03.314839Z","iopub.status.idle":"2022-11-29T02:23:03.635405Z","shell.execute_reply.started":"2022-11-29T02:23:03.314798Z","shell.execute_reply":"2022-11-29T02:23:03.628655Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Prediction:  0\nActual:  0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}